{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e90f30-03a7-43ee-ac65-6118297932d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "# pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58c6149-c4e0-4089-b40d-93466ab082fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twenty_eleven_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2011.csv', low_memory=False)\n",
    "twenty_thirteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2013.csv', low_memory=False)\n",
    "twenty_fifteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2015.csv', low_memory=False)\n",
    "\n",
    "# 2017's data has a lot of missing values and negative values. We don't consider using it at this moment\n",
    "# twenty_seventeen_df = pd.read_csv('schools_crdc_ap_exams_2017.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deeb8ed3-02b9-4ca7-8113-0b6f833a115d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Enrollment Data\n",
    "twenty_eleven_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2011.csv\", low_memory=False)\n",
    "twenty_thirteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2013.csv\", low_memory=False)\n",
    "twenty_fifteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2015.csv\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622e4f27-0519-40fd-8206-123959622d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           leaid       ncessch\n",
      "57179   400001.0  4.000010e+10\n",
      "57749   400019.0  4.000190e+10\n",
      "58049   400026.0  4.000260e+10\n",
      "58619   400056.0  4.000560e+10\n",
      "58799   400065.0  4.000650e+10\n",
      "...          ...           ...\n",
      "116129  409630.0  4.096300e+10\n",
      "116159  409630.0  4.096300e+10\n",
      "116189  409630.0  4.096300e+10\n",
      "116219  409630.0  4.096300e+10\n",
      "116249  409733.0  4.097330e+10\n",
      "\n",
      "[175 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# missing_id = twenty_eleven_df[twenty_eleven_df['ncessch'].isna()]\n",
    "# print(len(missing_id) / 30)\n",
    "\n",
    "# Function to process data that removes all NA rows or with negative values\n",
    "\n",
    "def data_validifier(dataframe, state_id):\n",
    "    # Getting rows with the required state_id\n",
    "    state_df = dataframe[dataframe['fips'] == state_id];\n",
    "    \n",
    "    # Aggregate Race and Sex\n",
    "    state_agg = state_df[(state_df['race'] == 99) & (state_df['sex'] == 99)]\n",
    "    \n",
    "    # Drop some columns we don't need at this moment\n",
    "    state_df_dropcolumn = state_agg.drop(columns=['students_AP_exam_all', 'students_AP_pass_all', 'fips', 'lep', 'disability', 'crdc_id', \n",
    "                                                'students_AP_exam_none', 'students_AP_pass_none', 'students_AP_exam_oneormore', 'sex', 'race'])\n",
    "    \n",
    "    # Drop NA Values(It's fine to have NA values for exam_all or pass_all\n",
    "    state_df_nona = state_df_dropcolumn.dropna()\n",
    "    \n",
    "    # Remove all rows with negative values\n",
    "    state_df_final = state_df_nona[(state_df_nona['students_AP_pass_oneormore'] >= 0)]\n",
    "    \n",
    "    # Return 2 tables, one with leaid and school id, one without\n",
    "    school_district_df = state_df_final[['leaid', 'ncessch']]\n",
    "    state_df_final = state_df_final.drop(columns=['leaid'])\n",
    "    \n",
    "    \n",
    "    return state_df_final, school_district_df\n",
    "\n",
    "# Get Arizona's valid df\n",
    "arizona_2011, arizona_2011_district = data_validifier(twenty_eleven_df, 4)\n",
    "arizona_2013, arizona_2013_district = data_validifier(twenty_thirteen_df, 4)\n",
    "arizona_2015, arizona_2015_district = data_validifier(twenty_fifteen_df, 4)\n",
    "\n",
    "print(arizona_2015_district)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb16ec2-c323-4e92-babb-ff45e8977388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process enrollment data\n",
    "def enrollment_processor(dataframe, state_id):\n",
    "    # Getting rows with the relevant state_id\n",
    "    state_enroll_df = dataframe[dataframe['fips'] == state_id]\n",
    "    \n",
    "    # Drop preenrollment \n",
    "    state_enroll_df = state_enroll_df.drop(columns=['psenrollment_crdc', 'crdc_id', 'fips'])\n",
    "    \n",
    "    # We need proportion of females and each races\n",
    "    # We don't care about disability or LEP here\n",
    "    state_enroll_relevant = state_enroll_df[(state_enroll_df['disability'] == 99) & (state_enroll_df['lep'] == 99)]\n",
    "    state_enroll_relevant = state_enroll_relevant.drop(columns=['disability', 'lep'])\n",
    "    \n",
    "    # We only want data with ncessch id\n",
    "    state_enroll_withid = state_enroll_relevant[~state_enroll_relevant['ncessch'].isna()]\n",
    "    \n",
    "    # We want proportion and check that with 99\n",
    "    state_enroll_final = state_enroll_withid[(state_enroll_withid['race'] == 99) | (state_enroll_withid['sex'] == 99)]\n",
    "    \n",
    "    return state_enroll_final\n",
    "\n",
    "\n",
    "arizona_enroll_2011 = enrollment_processor(twenty_eleven_enroll_df, 4)\n",
    "arizona_enroll_2013 = enrollment_processor(twenty_thirteen_enroll_df, 4)\n",
    "arizona_enroll_2015 = enrollment_processor(twenty_fifteen_enroll_df, 4)\n",
    "# We only care about schools that have AP passing one or more in previous table\n",
    "arizona_enroll_2011 = arizona_enroll_2011[arizona_enroll_2011['ncessch'].isin(arizona_2011['ncessch'])]\n",
    "arizona_enroll_2013 = arizona_enroll_2013[arizona_enroll_2013['ncessch'].isin(arizona_2013['ncessch'])]\n",
    "arizona_enroll_2015 = arizona_enroll_2015[arizona_enroll_2015['ncessch'].isin(arizona_2015['ncessch'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4919e73-321a-488d-9821-89edcb8dbf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "# Find the percentage of females and different races\n",
    "def find_percentage(dataframe):\n",
    "    total_enroll = dataframe[(dataframe['race'] == 99) & (dataframe['sex'] == 99)].copy()\n",
    "    total_enroll = total_enroll[['ncessch', 'enrollment_crdc']]\n",
    "    total_enroll.rename(columns={'enrollment_crdc' : 'total_enrollment'}, inplace=True)\n",
    "    \n",
    "    merged_total_df = pd.merge(total_enroll, dataframe)\n",
    "    \n",
    "    # Find percentage of female and merge\n",
    "    female_df = merged_total_df[(merged_total_df['sex'] == 2) & (merged_total_df['race'] == 99)].copy()\n",
    "    female_df['% female'] = female_df['enrollment_crdc'] / female_df['total_enrollment']\n",
    "    female_df = female_df[['ncessch', '% female']]\n",
    "    \n",
    "    \n",
    "    white_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 1)].copy()\n",
    "    white_df['% white'] = white_df['enrollment_crdc'] / white_df['total_enrollment']\n",
    "    white_df = white_df[['ncessch', '% white']]\n",
    "    \n",
    "    black_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 2)].copy()\n",
    "    black_df['% black'] = black_df['enrollment_crdc'] / black_df['total_enrollment']\n",
    "    black_df = black_df[['ncessch', '% black']]\n",
    "    \n",
    "    hispanic_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 3)].copy()\n",
    "    hispanic_df['% hispanic'] = hispanic_df['enrollment_crdc'] / hispanic_df['total_enrollment']\n",
    "    hispanic_df = hispanic_df[['ncessch', '% hispanic']]\n",
    "    \n",
    "    asian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 4)].copy()\n",
    "    asian_df['% asian'] = asian_df['enrollment_crdc'] / asian_df['total_enrollment']\n",
    "    asian_df = asian_df[['ncessch', '% asian']]\n",
    "    \n",
    "    american_indian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 5)].copy()\n",
    "    american_indian_df['% american_indian'] = american_indian_df['enrollment_crdc'] / american_indian_df['total_enrollment']\n",
    "    american_indian_df = american_indian_df[['ncessch', '% american_indian']]\n",
    "    \n",
    "    native_hawaiian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 6)].copy()\n",
    "    native_hawaiian_df['% native_hawaiian'] = native_hawaiian_df['enrollment_crdc'] / native_hawaiian_df['total_enrollment']\n",
    "    native_hawaiian_df = native_hawaiian_df[['ncessch', '% native_hawaiian']]\n",
    "    \n",
    "    twoormore_races_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 7)].copy()\n",
    "    twoormore_races_df['% two_or_more_races'] = twoormore_races_df['enrollment_crdc'] / twoormore_races_df['total_enrollment']\n",
    "    twoormore_races_df = twoormore_races_df[['ncessch', '% two_or_more_races']]\n",
    "    \n",
    "    merge_female_df = pd.merge(dataframe, female_df, on='ncessch')\n",
    "    merge_white_df = pd.merge(merge_female_df, white_df, on='ncessch')\n",
    "    merge_black_df = pd.merge(merge_white_df, black_df, on='ncessch')\n",
    "    merge_hispanic_df = pd.merge(merge_black_df, hispanic_df, on='ncessch')\n",
    "    merge_asian_df = pd.merge(merge_hispanic_df, asian_df, on='ncessch')\n",
    "    merge_american_indian_df = pd.merge(merge_asian_df, american_indian_df, on='ncessch')\n",
    "    merge_native_hawaiian_df = pd.merge(merge_american_indian_df, native_hawaiian_df, on='ncessch')\n",
    "    merge_twoormorerace_df = pd.merge(merge_native_hawaiian_df, twoormore_races_df, on='ncessch')\n",
    "    final_df = pd.merge(merge_twoormorerace_df, total_enroll, on='ncessch')\n",
    "    \n",
    "    final_df = final_df[(final_df['race'] == 99) & (final_df['sex'] == 99)]\n",
    "    final_df = final_df.drop(columns=['race', 'sex', 'enrollment_crdc', 'leaid'])\n",
    "    return final_df\n",
    "\n",
    "def get_info_df(percentage_df, score_df):\n",
    "    \n",
    "    info_df = pd.merge(percentage_df, score_df, on='ncessch')\n",
    "    year_col = info_df['year_y']\n",
    "    info_df = info_df.drop(columns=['year_x', 'year_y'])\n",
    "    info_df.insert(1, 'year', year_col)\n",
    "    return info_df\n",
    "\n",
    "arizona_2011_enroll_percent = find_percentage(arizona_enroll_2011)\n",
    "arizona_2013_enroll_percent = find_percentage(arizona_enroll_2013)\n",
    "arizona_2015_enroll_percent = find_percentage(arizona_enroll_2015)\n",
    "\n",
    "arizona_2011_info_df = get_info_df(arizona_2011_enroll_percent, arizona_2011)\n",
    "arizona_2013_info_df = get_info_df(arizona_2013_enroll_percent, arizona_2013)\n",
    "arizona_2015_info_df = get_info_df(arizona_2015_enroll_percent, arizona_2015)\n",
    "print(arizona_2011_info_df['ncessch'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b3fcd7-7c00-494c-909b-78c637f73ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concat Data for training purpose\n",
    "# Planning to use 2011 and 2013 for training\n",
    "train_data = pd.concat([arizona_2011_info_df, arizona_2013_info_df], ignore_index = True)\n",
    "train_feature = train_data.drop(columns=['students_AP_pass_oneormore'])\n",
    "train_target = train_data[['students_AP_pass_oneormore']]\n",
    "\n",
    "# Test Data is 2015 without passing info\n",
    "test_data = arizona_2015_info_df\n",
    "test_feature = test_data.drop(columns=['students_AP_pass_oneormore'])\n",
    "test_target = test_data[['students_AP_pass_oneormore']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf82bf1-464b-47d1-a648-d9bc7b1ae79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_feature)\n",
    "X_test = scaler.transform(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdf6f2-1fd8-4792-af48-946267ef1be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 400001.0: MSE = 12996.00\n",
      "District 400019.0: MSE = 100.00\n",
      "District 400026.0: MSE = 64.00\n",
      "District 400056.0: MSE = 26244.00\n",
      "District 400065.0: MSE = 0.00\n",
      "District 400081.0: MSE = 1521.00\n",
      "District 400097.0: MSE = 2025.00\n",
      "District 400112.0: MSE = 1024.00\n",
      "District 400129.0: MSE = 25.00\n",
      "District 400202.0: MSE = 9.00\n",
      "District 400211.0: MSE = 16.00\n",
      "District 400223.0: MSE = 1.00\n",
      "District 400225.0: MSE = 4556.25\n",
      "District 400327.0: MSE = 81.00\n",
      "District 400427.0: MSE = 33124.00\n",
      "District 400432.0: MSE = 0.00\n",
      "District 400450.0: MSE = 2877.15\n",
      "District 400608.0: MSE = 15129.00\n",
      "District 400653.0: MSE = 64.00\n",
      "District 400680.0: MSE = 4267.33\n",
      "District 400778.0: MSE = 9.00\n",
      "District 400790.0: MSE = 289.00\n",
      "District 400818.0: MSE = 4489.00\n",
      "District 400829.0: MSE = 784.00\n",
      "District 400830.0: MSE = 5041.00\n",
      "District 400831.0: MSE = 7921.00\n",
      "District 400843.0: MSE = 4.00\n",
      "District 400862.0: MSE = 49.00\n",
      "District 400878.0: MSE = 17030.25\n",
      "District 400897.0: MSE = 6084.00\n",
      "District 400898.0: MSE = 9216.00\n",
      "District 400903.0: MSE = 400.00\n",
      "District 400904.0: MSE = 2304.00\n",
      "District 400909.0: MSE = 1.00\n",
      "District 401180.0: MSE = 0.00\n",
      "District 401410.0: MSE = 153.67\n",
      "District 401460.0: MSE = 4356.00\n",
      "District 401740.0: MSE = 169.00\n",
      "District 401760.0: MSE = 70728.50\n",
      "District 401870.0: MSE = 75069.00\n",
      "District 402320.0: MSE = 0.00\n",
      "District 402530.0: MSE = 729.00\n",
      "District 402690.0: MSE = 552.50\n",
      "District 402860.0: MSE = 68.00\n",
      "District 402920.0: MSE = 8281.00\n",
      "District 403010.0: MSE = 2209.00\n",
      "District 403040.0: MSE = 169.00\n",
      "District 403400.0: MSE = 15537.33\n",
      "District 403450.0: MSE = 11866.14\n",
      "District 403780.0: MSE = 2994.50\n",
      "District 403870.0: MSE = 1600.00\n",
      "District 403990.0: MSE = 36.00\n",
      "District 404630.0: MSE = 24809.00\n",
      "District 404720.0: MSE = 441.00\n",
      "District 404970.0: MSE = 15275.56\n",
      "District 405070.0: MSE = 169.00\n",
      "District 405320.0: MSE = 9.00\n",
      "District 405530.0: MSE = 9.00\n",
      "District 405820.0: MSE = 49.00\n",
      "District 405930.0: MSE = 8733.20\n",
      "District 406070.0: MSE = 3721.00\n",
      "District 406250.0: MSE = 5656.57\n",
      "District 406330.0: MSE = 2626.45\n",
      "District 406580.0: MSE = 729.00\n",
      "District 406730.0: MSE = 1849.00\n",
      "District 407300.0: MSE = 3578.50\n",
      "District 407570.0: MSE = 27693.50\n",
      "District 407700.0: MSE = 289.00\n",
      "District 407750.0: MSE = 3336.40\n",
      "District 408170.0: MSE = 2762.00\n",
      "District 408280.0: MSE = 256.00\n",
      "District 408340.0: MSE = 470.45\n",
      "District 408520.0: MSE = 14614.50\n",
      "District 408800.0: MSE = 11597.04\n",
      "District 408850.0: MSE = 9198.75\n",
      "District 409190.0: MSE = 1521.00\n",
      "District 409460.0: MSE = 324.00\n",
      "District 409630.0: MSE = 6028.20\n",
      "District 409733.0: MSE = 9216.00\n"
     ]
    }
   ],
   "source": [
    "# Use DecisionTreeRegressor to fit the model\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "model = DecisionTreeRegressor(random_state = 482)\n",
    "\n",
    "# Function to fit and predict different metrics\n",
    "def predictor():\n",
    "    \n",
    "    # Fit and predict students_AP_exam_none\n",
    "    model.fit(X_train, train_target)\n",
    "    predict_ap_passing = model.predict(X_test)\n",
    "    test_result = test_data.copy()\n",
    "    test_result.rename(columns={'students_AP_pass_oneormore' : 'actual_students_AP_pass_oneormore'}, inplace=True)\n",
    "    test_result['predicted_students_AP_pass_oneormore'] = predict_ap_passing\n",
    "    test_result = pd.merge(test_result, arizona_2015_district, on='ncessch')\n",
    "    return test_result\n",
    "    \n",
    "test_result = predictor()\n",
    "\n",
    "# Calculate the MSE by each district\n",
    "grouped = test_result.groupby('leaid')\n",
    "mse_by_district = {}\n",
    "\n",
    "for district_id, group in grouped:\n",
    "    mse = mean_squared_error(group['actual_students_AP_pass_oneormore'], group['predicted_students_AP_pass_oneormore'])\n",
    "    mse_by_district[district_id] = mse\n",
    "    \n",
    "for district_id, mse in mse_by_district.items():\n",
    "    print(f\"District {district_id}: MSE = {mse:.2f}\")    \n",
    "    \n",
    "\n",
    "plt.figure(figsize=(100,50), dpi=500)\n",
    "plot_tree(model, filled=True, feature_names=train_feature.columns, rounded=True, fontsize=7)\n",
    "plt.savefig('APEducationData/decision_tree_plot.png', bbox_inches='tight')  # Save the plot to a file\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d854c-abcd-4065-b1f6-b86adf47cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modules",
   "language": "python",
   "name": "haytham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

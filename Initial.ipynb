{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e90f30-03a7-43ee-ac65-6118297932d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "# pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58c6149-c4e0-4089-b40d-93466ab082fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twenty_eleven_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2011.csv', low_memory=False)\n",
    "twenty_thirteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2013.csv', low_memory=False)\n",
    "twenty_fifteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2015.csv', low_memory=False)\n",
    "\n",
    "# 2017's data has a lot of missing values and negative values. We don't consider using it at this moment\n",
    "# twenty_seventeen_df = pd.read_csv('schools_crdc_ap_exams_2017.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deeb8ed3-02b9-4ca7-8113-0b6f833a115d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Enrollment Data\n",
    "twenty_eleven_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2011.csv\", low_memory=False)\n",
    "twenty_thirteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2013.csv\", low_memory=False)\n",
    "twenty_fifteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2015.csv\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "26d2ed74-c786-4c81-a9dc-a230c3cfbe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weird_twenty_eleven_df = twenty_eleven_df[\n",
    "#     ((twenty_eleven_df['students_AP_exam_oneormore'] > twenty_eleven_df['students_AP_pass_oneormore']) & (twenty_eleven_df['students_AP_pass_oneormore'] >= 0)) | \n",
    "#     ((twenty_eleven_df['students_AP_exam_all'] > twenty_eleven_df['students_AP_exam_oneormore']) & (twenty_eleven_df['students_AP_exam_oneormore'] >= 0)) |\n",
    "#     ((twenty_eleven_df['students_AP_pass_all'] > twenty_eleven_df['students_AP_exam_all']) & (twenty_eleven_df['students_AP_exam_all'] >= 0))\n",
    "                                                                                                                        \n",
    "# ]\n",
    "# number_schools = weird_twenty_eleven_df['crdc_id'].nunique()\n",
    "# print(len(weird_twenty_eleven_df))\n",
    "# print(number_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "622e4f27-0519-40fd-8206-123959622d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  students_AP_pass_oneormore       ncessch\n",
      "57839   2011                       129.0  4.000010e+10\n",
      "58379   2011                        11.0  4.000190e+10\n",
      "58709   2011                         4.0  4.000260e+10\n",
      "58979   2011                         4.0  4.000430e+10\n",
      "59669   2011                         4.0  4.000740e+10\n",
      "...      ...                         ...           ...\n",
      "115049  2011                         8.0  4.096300e+10\n",
      "115079  2011                        56.0  4.096300e+10\n",
      "115109  2011                        15.0  4.096300e+10\n",
      "115139  2011                        86.0  4.096300e+10\n",
      "115199  2011                         4.0  4.097330e+10\n",
      "\n",
      "[126 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# missing_id = twenty_eleven_df[twenty_eleven_df['ncessch'].isna()]\n",
    "# print(len(missing_id) / 30)\n",
    "\n",
    "# Function to process data that removes all NA rows or with negative values\n",
    "\n",
    "def data_validifier(dataframe, state_id):\n",
    "    # Getting rows with the required state_id\n",
    "    state_df = dataframe[dataframe['fips'] == state_id];\n",
    "    \n",
    "    # Aggregate Race and Sex\n",
    "    state_agg = state_df[(state_df['race'] == 99) & (state_df['sex'] == 99)]\n",
    "    \n",
    "    # Drop some columns we don't need at this moment\n",
    "    state_df_dropcolumn = state_agg.drop(columns=['students_AP_exam_all', 'students_AP_pass_all', 'fips', 'lep', 'disability', 'leaid', 'crdc_id', \n",
    "                                                'students_AP_exam_none', 'students_AP_pass_none', 'students_AP_exam_oneormore', 'sex', 'race'])\n",
    "    \n",
    "    # Drop NA Values(It's fine to have NA values for exam_all or pass_all\n",
    "    state_df_nona = state_df_dropcolumn.dropna()\n",
    "    \n",
    "    # Remove all rows with negative values\n",
    "    state_df_final = state_df_nona[(state_df_nona['students_AP_pass_oneormore'] >= 0)]\n",
    "    \n",
    "    return state_df_final\n",
    "\n",
    "# Get Arizona's valid df\n",
    "arizona_2011 = data_validifier(twenty_eleven_df, 4)\n",
    "arizona_2013 = data_validifier(twenty_thirteen_df, 4)\n",
    "arizona_2015 = data_validifier(twenty_fifteen_df, 4)\n",
    "\n",
    "print(arizona_2011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fb16ec2-c323-4e92-babb-ff45e8977388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n",
      "1250\n"
     ]
    }
   ],
   "source": [
    "# Function to process enrollment data\n",
    "def enrollment_processor(dataframe, state_id):\n",
    "    # Getting rows with the relevant state_id\n",
    "    state_enroll_df = dataframe[dataframe['fips'] == state_id]\n",
    "    \n",
    "    # Drop preenrollment \n",
    "    state_enroll_df = state_enroll_df.drop(columns=['psenrollment_crdc', 'crdc_id', 'fips'])\n",
    "    \n",
    "    # We need proportion of females and each races\n",
    "    # We don't care about disability or LEP here\n",
    "    state_enroll_relevant = state_enroll_df[(state_enroll_df['disability'] == 99) & (state_enroll_df['lep'] == 99)]\n",
    "    state_enroll_relevant = state_enroll_relevant.drop(columns=['disability', 'lep'])\n",
    "    \n",
    "    # We only want data with ncessch id\n",
    "    state_enroll_withid = state_enroll_relevant[~state_enroll_relevant['ncessch'].isna()]\n",
    "    \n",
    "    # We want proportion and check that with 99\n",
    "    state_enroll_final = state_enroll_withid[(state_enroll_withid['race'] == 99) | (state_enroll_withid['sex'] == 99)]\n",
    "    \n",
    "    return state_enroll_final\n",
    "\n",
    "\n",
    "arizona_enroll_2011 = enrollment_processor(twenty_eleven_enroll_df, 4)\n",
    "arizona_enroll_2013 = enrollment_processor(twenty_thirteen_enroll_df, 4)\n",
    "arizona_enroll_2015 = enrollment_processor(twenty_fifteen_enroll_df, 4)\n",
    "print(len(arkansas_enroll_2015))\n",
    "# We only care about schools that have AP passing one or more in previous table\n",
    "arizona_enroll_2011 = arizona_enroll_2011[arizona_enroll_2011['ncessch'].isin(arizona_2011['ncessch'])]\n",
    "arizona_enroll_2013 = arizona_enroll_2013[arizona_enroll_2013['ncessch'].isin(arizona_2013['ncessch'])]\n",
    "arizona_enroll_2015 = arizona_enroll_2015[arizona_enroll_2015['ncessch'].isin(arizona_2015['ncessch'])]\n",
    "\n",
    "print(len(arizona_enroll_2011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4919e73-321a-488d-9821-89edcb8dbf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncessch</th>\n",
       "      <th>year</th>\n",
       "      <th>leaid</th>\n",
       "      <th>% female</th>\n",
       "      <th>% white</th>\n",
       "      <th>% black</th>\n",
       "      <th>% hispanic</th>\n",
       "      <th>% asian</th>\n",
       "      <th>% american_indian</th>\n",
       "      <th>% native_hawaiian</th>\n",
       "      <th>% two_or_more_races</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>students_AP_pass_oneormore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.000010e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400001.0</td>\n",
       "      <td>0.496606</td>\n",
       "      <td>0.879525</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.026018</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.000190e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400019.0</td>\n",
       "      <td>0.628483</td>\n",
       "      <td>0.801858</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>323.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000260e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400026.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>136.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000560e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400056.0</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>0.634638</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.221827</td>\n",
       "      <td>0.051008</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040332</td>\n",
       "      <td>843.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.000650e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400065.0</td>\n",
       "      <td>0.487209</td>\n",
       "      <td>0.796512</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.123256</td>\n",
       "      <td>0.022093</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>860.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000810e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400081.0</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>0.378190</td>\n",
       "      <td>0.058005</td>\n",
       "      <td>0.475638</td>\n",
       "      <td>0.037123</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>431.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.000970e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400097.0</td>\n",
       "      <td>0.533541</td>\n",
       "      <td>0.792512</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.113885</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>641.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.001120e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400112.0</td>\n",
       "      <td>0.504594</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.039816</td>\n",
       "      <td>0.133997</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.001290e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400129.0</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.002020e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400202.0</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>162.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.002110e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400211.0</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.002230e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400223.0</td>\n",
       "      <td>0.445517</td>\n",
       "      <td>0.473103</td>\n",
       "      <td>0.051034</td>\n",
       "      <td>0.299310</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>725.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.002250e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400225.0</td>\n",
       "      <td>0.528213</td>\n",
       "      <td>0.725705</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.147335</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>0.025078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>638.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.003270e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400327.0</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.040670</td>\n",
       "      <td>836.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.004270e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400427.0</td>\n",
       "      <td>0.525098</td>\n",
       "      <td>0.626476</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.217520</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.075787</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.004320e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400432.0</td>\n",
       "      <td>0.511155</td>\n",
       "      <td>0.665362</td>\n",
       "      <td>0.094716</td>\n",
       "      <td>0.163992</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>5110.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.509543</td>\n",
       "      <td>0.196645</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.642568</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.509543</td>\n",
       "      <td>0.196645</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.642568</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.484579</td>\n",
       "      <td>0.415421</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.369159</td>\n",
       "      <td>0.064953</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.035514</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.475270</td>\n",
       "      <td>0.285389</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>0.500284</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.475270</td>\n",
       "      <td>0.285389</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>0.500284</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.511558</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>0.362312</td>\n",
       "      <td>0.021608</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.004500e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400450.0</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.511558</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>0.362312</td>\n",
       "      <td>0.021608</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.006080e+10</td>\n",
       "      <td>2015</td>\n",
       "      <td>400608.0</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.477151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>744.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncessch  year     leaid  % female   % white   % black  % hispanic  \\\n",
       "0   4.000010e+10  2015  400001.0  0.496606  0.879525  0.012443    0.073529   \n",
       "1   4.000190e+10  2015  400019.0  0.628483  0.801858  0.012384    0.095975   \n",
       "2   4.000260e+10  2015  400026.0  0.500000  0.779412  0.000000    0.139706   \n",
       "3   4.000560e+10  2015  400056.0  0.715302  0.634638  0.036773    0.221827   \n",
       "4   4.000650e+10  2015  400065.0  0.487209  0.796512  0.015116    0.123256   \n",
       "5   4.000810e+10  2015  400081.0  0.554524  0.378190  0.058005    0.475638   \n",
       "6   4.000970e+10  2015  400097.0  0.533541  0.792512  0.010920    0.113885   \n",
       "7   4.001120e+10  2015  400112.0  0.504594  0.777182  0.039816    0.133997   \n",
       "8   4.001290e+10  2015  400129.0  0.422680  0.376289  0.051546    0.515464   \n",
       "9   4.002020e+10  2015  400202.0  0.530864  0.654321  0.061728    0.191358   \n",
       "10  4.002110e+10  2015  400211.0  0.540541  0.842342  0.009009    0.139640   \n",
       "11  4.002230e+10  2015  400223.0  0.445517  0.473103  0.051034    0.299310   \n",
       "12  4.002250e+10  2015  400225.0  0.528213  0.725705  0.039185    0.147335   \n",
       "13  4.003270e+10  2015  400327.0  0.540670  0.474880  0.037081    0.406699   \n",
       "14  4.004270e+10  2015  400427.0  0.525098  0.626476  0.037402    0.217520   \n",
       "15  4.004320e+10  2015  400432.0  0.511155  0.665362  0.094716    0.163992   \n",
       "16  4.004500e+10  2015  400450.0  0.509543  0.196645  0.113360    0.642568   \n",
       "17  4.004500e+10  2015  400450.0  0.509543  0.196645  0.113360    0.642568   \n",
       "18  4.004500e+10  2015  400450.0  0.484579  0.415421  0.098598    0.369159   \n",
       "19  4.004500e+10  2015  400450.0  0.475270  0.285389  0.137010    0.500284   \n",
       "20  4.004500e+10  2015  400450.0  0.475270  0.285389  0.137010    0.500284   \n",
       "21  4.004500e+10  2015  400450.0  0.493970  0.511558  0.059296    0.362312   \n",
       "22  4.004500e+10  2015  400450.0  0.493970  0.511558  0.059296    0.362312   \n",
       "23  4.006080e+10  2015  400608.0  0.467742  0.408602  0.009409    0.049731   \n",
       "\n",
       "     % asian  % american_indian  % native_hawaiian  % two_or_more_races  \\\n",
       "0   0.026018           0.002262           0.002262             0.003959   \n",
       "1   0.021672           0.021672           0.006192             0.040248   \n",
       "2   0.000000           0.051471           0.000000             0.029412   \n",
       "3   0.051008           0.015421           0.000000             0.040332   \n",
       "4   0.022093           0.002326           0.004651             0.036047   \n",
       "5   0.037123           0.016241           0.004640             0.030162   \n",
       "6   0.020281           0.020281           0.003120             0.039002   \n",
       "7   0.014548           0.005360           0.005360             0.023737   \n",
       "8   0.036082           0.020619           0.000000             0.000000   \n",
       "9   0.024691           0.012346           0.012346             0.043210   \n",
       "10  0.000000           0.009009           0.000000             0.000000   \n",
       "11  0.108966           0.009655           0.002759             0.055172   \n",
       "12  0.062696           0.025078           0.000000             0.000000   \n",
       "13  0.029904           0.008373           0.002392             0.040670   \n",
       "14  0.016732           0.024114           0.001969             0.075787   \n",
       "15  0.019569           0.042466           0.008415             0.005479   \n",
       "16  0.016194           0.007519           0.004049             0.019665   \n",
       "17  0.016194           0.007519           0.004049             0.019665   \n",
       "18  0.064953           0.008879           0.007477             0.035514   \n",
       "19  0.024446           0.012507           0.002274             0.038090   \n",
       "20  0.024446           0.012507           0.002274             0.038090   \n",
       "21  0.021608           0.005025           0.003518             0.036683   \n",
       "22  0.021608           0.005025           0.003518             0.036683   \n",
       "23  0.477151           0.000000           0.005376             0.049731   \n",
       "\n",
       "    total_enrollment  students_AP_pass_oneormore  \n",
       "0             1768.0                       248.0  \n",
       "1              323.0                        26.0  \n",
       "2              136.0                        24.0  \n",
       "3              843.0                        56.0  \n",
       "4              860.0                        11.0  \n",
       "5              431.0                        51.0  \n",
       "6              641.0                        85.0  \n",
       "7             1306.0                        36.0  \n",
       "8              194.0                        16.0  \n",
       "9              162.0                        11.0  \n",
       "10             222.0                         8.0  \n",
       "11             725.0                        17.0  \n",
       "12             638.0                       249.0  \n",
       "13             836.0                        37.0  \n",
       "14            2032.0                         4.0  \n",
       "15            5110.0                        17.0  \n",
       "16            1729.0                        14.0  \n",
       "17            1729.0                        88.0  \n",
       "18            2140.0                        82.0  \n",
       "19            1759.0                         4.0  \n",
       "20            1759.0                        69.0  \n",
       "21            1990.0                         7.0  \n",
       "22            1990.0                       123.0  \n",
       "23             744.0                       290.0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data together\n",
    "def find_percentage(dataframe, score_df):\n",
    "    total_enroll = dataframe[(dataframe['race'] == 99) & (dataframe['sex'] == 99)].copy()\n",
    "    total_enroll = total_enroll[['ncessch', 'enrollment_crdc']]\n",
    "    total_enroll.rename(columns={'enrollment_crdc' : 'total_enrollment'}, inplace=True)\n",
    "    \n",
    "    merged_total_df = pd.merge(total_enroll, dataframe)\n",
    "    \n",
    "    # Find percentage of female and merge\n",
    "    female_df = merged_total_df[(merged_total_df['sex'] == 2) & (merged_total_df['race'] == 99)].copy()\n",
    "    female_df['% female'] = female_df['enrollment_crdc'] / female_df['total_enrollment']\n",
    "    female_df = female_df[['ncessch', '% female']]\n",
    "    \n",
    "    \n",
    "    white_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 1)].copy()\n",
    "    white_df['% white'] = white_df['enrollment_crdc'] / white_df['total_enrollment']\n",
    "    white_df = white_df[['ncessch', '% white']]\n",
    "    \n",
    "    black_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 2)].copy()\n",
    "    black_df['% black'] = black_df['enrollment_crdc'] / black_df['total_enrollment']\n",
    "    black_df = black_df[['ncessch', '% black']]\n",
    "    \n",
    "    hispanic_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 3)].copy()\n",
    "    hispanic_df['% hispanic'] = hispanic_df['enrollment_crdc'] / hispanic_df['total_enrollment']\n",
    "    hispanic_df = hispanic_df[['ncessch', '% hispanic']]\n",
    "    \n",
    "    asian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 4)].copy()\n",
    "    asian_df['% asian'] = asian_df['enrollment_crdc'] / asian_df['total_enrollment']\n",
    "    asian_df = asian_df[['ncessch', '% asian']]\n",
    "    \n",
    "    american_indian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 5)].copy()\n",
    "    american_indian_df['% american_indian'] = american_indian_df['enrollment_crdc'] / american_indian_df['total_enrollment']\n",
    "    american_indian_df = american_indian_df[['ncessch', '% american_indian']]\n",
    "    \n",
    "    native_hawaiian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 6)].copy()\n",
    "    native_hawaiian_df['% native_hawaiian'] = native_hawaiian_df['enrollment_crdc'] / native_hawaiian_df['total_enrollment']\n",
    "    native_hawaiian_df = native_hawaiian_df[['ncessch', '% native_hawaiian']]\n",
    "    \n",
    "    twoormore_races_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 7)].copy()\n",
    "    twoormore_races_df['% two_or_more_races'] = twoormore_races_df['enrollment_crdc'] / twoormore_races_df['total_enrollment']\n",
    "    twoormore_races_df = twoormore_races_df[['ncessch', '% two_or_more_races']]\n",
    "    \n",
    "    merge_female_df = pd.merge(dataframe, female_df, on='ncessch')\n",
    "    merge_white_df = pd.merge(merge_female_df, white_df, on='ncessch')\n",
    "    merge_black_df = pd.merge(merge_white_df, black_df, on='ncessch')\n",
    "    merge_hispanic_df = pd.merge(merge_black_df, hispanic_df, on='ncessch')\n",
    "    merge_asian_df = pd.merge(merge_hispanic_df, asian_df, on='ncessch')\n",
    "    merge_american_indian_df = pd.merge(merge_asian_df, american_indian_df, on='ncessch')\n",
    "    merge_native_hawaiian_df = pd.merge(merge_american_indian_df, native_hawaiian_df, on='ncessch')\n",
    "    merge_twoormorerace_df = pd.merge(merge_native_hawaiian_df, twoormore_races_df, on='ncessch')\n",
    "    final_df = pd.merge(merge_twoormorerace_df, total_enroll, on='ncessch')\n",
    "    \n",
    "    final_df = final_df[(final_df['race'] == 99) & (final_df['sex'] == 99)]\n",
    "    final_df = final_df.drop(columns=['race', 'sex', 'enrollment_crdc'])\n",
    "    final_df = pd.merge(final_df, score_df, on='ncessch')\n",
    "    year_col = final_df['year_y']\n",
    "    final_df = final_df.drop(columns=['year_x', 'year_y'])\n",
    "    final_df.insert(1, 'year', year_col)\n",
    "    return final_df\n",
    "    \n",
    "arizona_2011_info_df = find_percentage(arizona_enroll_2015, arizona_2015)\n",
    "arizona_2011_info_df.head(24)\n",
    "# print(arizona_2011_info_df['ncessch'].nunique())\n",
    "# print(arizona_2011_info_df['leaid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414aa14-80b4-47a6-8f21-0e29c7494683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0b3fcd7-7c00-494c-909b-78c637f73ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ncessch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  race       ncessch\n",
       "0     1   1.0  6.000010e+10\n",
       "1     1   3.0  6.000010e+10\n",
       "2     1  99.0  6.000010e+10\n",
       "3     2   1.0  6.000010e+10\n",
       "4     2  99.0  6.000010e+10\n",
       "..  ...   ...           ...\n",
       "95    2   1.0  6.000201e+10\n",
       "96    2   4.0  6.000201e+10\n",
       "97    2  99.0  6.000201e+10\n",
       "98   99   1.0  6.000201e+10\n",
       "99   99   4.0  6.000201e+10\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat Data for training purpose\n",
    "# Planning to use 2011 and 2013 for training\n",
    "\n",
    "train_data = pd.concat([california_2011, california_2013], ignore_index = True)\n",
    "\n",
    "# Drop the year column \n",
    "# Reset Index for test data\n",
    "# train_data = train_data.drop(columns=['year'])\n",
    "# test_data = california_2015.drop(columns=['year']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_feature = train_data.drop(columns=['students_AP_pass_none', 'students_AP_exam_none', 'students_AP_exam_oneormore', 'students_AP_pass_oneormore'])\n",
    "train_none_ap = train_data['students_AP_exam_none']\n",
    "train_none_passing = train_data['students_AP_pass_none']\n",
    "train_oneormore_ap = train_data['students_AP_exam_oneormore']\n",
    "train_oneormore_passing = train_data['students_AP_pass_oneormore']\n",
    "\n",
    "test_feature = test_data.drop(columns=['students_AP_pass_none', 'students_AP_exam_none', 'students_AP_exam_oneormore', 'students_AP_pass_oneormore'])\n",
    "test_none_ap = test_data['students_AP_exam_none']\n",
    "test_none_passing = test_data['students_AP_pass_none']\n",
    "test_oneormore_ap = test_data['students_AP_exam_oneormore']\n",
    "test_oneormore_passing = test_data['students_AP_pass_oneormore']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2bf82bf1-464b-47d1-a648-d9bc7b1ae79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_feature)\n",
    "X_test = scaler.transform(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76cdf6f2-1fd8-4792-af48-946267ef1be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Students Taking No AP exams in California in 2015:  1696.0434014657346\n",
      "MSE for Students Passing No AP exams in California in 2015:  1816.2829910415514\n",
      "MSE for Students Taking One or More AP exams in California in 2015:  12083.408802793369\n",
      "MSE for Students Passing One or More AP exams in California in 2015:  5679.750827187407\n"
     ]
    }
   ],
   "source": [
    "# Use RandomForestRegressor to fit the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = RandomForestRegressor(random_state = 482)\n",
    "\n",
    "# Function to fit and predict different metrics\n",
    "def predictor():\n",
    "    \n",
    "    # Fit and predict students_AP_exam_none\n",
    "    model.fit(X_train, train_none_ap)\n",
    "    predict_none_ap = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_pass_none    \n",
    "    model.fit(X_train, train_none_passing)\n",
    "    predict_none_passing = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_exam_oneormore\n",
    "    model.fit(X_train, train_oneormore_ap)\n",
    "    predict_oneormore_ap = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_pass_oneormore\n",
    "    model.fit(X_train, train_oneormore_passing)\n",
    "    predict_oneormore_passing = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MSE metrics for each\n",
    "    none_ap_mse = mean_squared_error(predict_none_ap, test_none_ap)\n",
    "    none_passing_mse = mean_squared_error(predict_none_passing, test_none_passing)\n",
    "    oneormore_ap_mse = mean_squared_error(predict_oneormore_ap, test_oneormore_ap)\n",
    "    oneormore_passing_mse = mean_squared_error(predict_oneormore_passing, test_oneormore_passing)\n",
    "    \n",
    "    return none_ap_mse, none_passing_mse, oneormore_ap_mse, oneormore_passing_mse\n",
    "\n",
    "none_ap_mse, none_passing_mse, oneormore_ap_mse, oneormore_passing_mse = predictor()\n",
    "print(\"MSE for Students Taking No AP exams in California in 2015: \", none_ap_mse)\n",
    "print(\"MSE for Students Passing No AP exams in California in 2015: \", none_passing_mse)\n",
    "print(\"MSE for Students Taking One or More AP exams in California in 2015: \", oneormore_ap_mse)\n",
    "print(\"MSE for Students Passing One or More AP exams in California in 2015: \", oneormore_passing_mse)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d854c-abcd-4065-b1f6-b86adf47cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modules",
   "language": "python",
   "name": "haytham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e90f30-03a7-43ee-ac65-6118297932d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "# pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58c6149-c4e0-4089-b40d-93466ab082fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twenty_eleven_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2011.csv', low_memory=False)\n",
    "twenty_thirteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2013.csv', low_memory=False)\n",
    "twenty_fifteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2015.csv', low_memory=False)\n",
    "\n",
    "# 2017's data has a lot of missing values and negative values. We don't consider using it at this moment\n",
    "# twenty_seventeen_df = pd.read_csv('schools_crdc_ap_exams_2017.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deeb8ed3-02b9-4ca7-8113-0b6f833a115d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Enrollment Data\n",
    "twenty_eleven_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2011.csv\", low_memory=False)\n",
    "twenty_thirteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2013.csv\", low_memory=False)\n",
    "twenty_fifteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2015.csv\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622e4f27-0519-40fd-8206-123959622d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           leaid       ncessch\n",
      "57179   400001.0  4.000010e+10\n",
      "57749   400019.0  4.000190e+10\n",
      "58049   400026.0  4.000260e+10\n",
      "58619   400056.0  4.000560e+10\n",
      "58799   400065.0  4.000650e+10\n",
      "...          ...           ...\n",
      "116129  409630.0  4.096300e+10\n",
      "116159  409630.0  4.096300e+10\n",
      "116189  409630.0  4.096300e+10\n",
      "116219  409630.0  4.096300e+10\n",
      "116249  409733.0  4.097330e+10\n",
      "\n",
      "[175 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# missing_id = twenty_eleven_df[twenty_eleven_df['ncessch'].isna()]\n",
    "# print(len(missing_id) / 30)\n",
    "\n",
    "# Function to process data that removes all NA rows or with negative values\n",
    "\n",
    "def data_validifier(dataframe, state_id):\n",
    "    # Getting rows with the required state_id\n",
    "    state_df = dataframe[dataframe['fips'] == state_id];\n",
    "    \n",
    "    # Aggregate Race and Sex\n",
    "    state_agg = state_df[(state_df['race'] == 99) & (state_df['sex'] == 99)]\n",
    "    \n",
    "    # Drop some columns we don't need at this moment\n",
    "    state_df_dropcolumn = state_agg.drop(columns=['students_AP_exam_all', 'students_AP_pass_all', 'fips', 'lep', 'disability', 'crdc_id', \n",
    "                                                'students_AP_exam_none', 'students_AP_pass_none', 'students_AP_exam_oneormore', 'sex', 'race'])\n",
    "    \n",
    "    # Drop NA Values(It's fine to have NA values for exam_all or pass_all\n",
    "    state_df_nona = state_df_dropcolumn.dropna()\n",
    "    \n",
    "    # Remove all rows with negative values\n",
    "    state_df_final = state_df_nona[(state_df_nona['students_AP_pass_oneormore'] >= 0)]\n",
    "    \n",
    "    # Return 2 tables, one with leaid and school id, one without\n",
    "    school_district_df = state_df_final[['leaid', 'ncessch']]\n",
    "    state_df_final = state_df_final.drop(columns=['leaid'])\n",
    "    \n",
    "    \n",
    "    return state_df_final, school_district_df\n",
    "\n",
    "# Get Arizona's valid df\n",
    "arizona_2011, arizona_2011_district = data_validifier(twenty_eleven_df, 4)\n",
    "arizona_2013, arizona_2013_district = data_validifier(twenty_thirteen_df, 4)\n",
    "arizona_2015, arizona_2015_district = data_validifier(twenty_fifteen_df, 4)\n",
    "\n",
    "print(arizona_2015_district)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb16ec2-c323-4e92-babb-ff45e8977388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process enrollment data\n",
    "def enrollment_processor(dataframe, state_id):\n",
    "    # Getting rows with the relevant state_id\n",
    "    state_enroll_df = dataframe[dataframe['fips'] == state_id]\n",
    "    \n",
    "    # Drop preenrollment \n",
    "    state_enroll_df = state_enroll_df.drop(columns=['psenrollment_crdc', 'crdc_id', 'fips'])\n",
    "    \n",
    "    # We need proportion of females and each races\n",
    "    # We don't care about disability or LEP here\n",
    "    state_enroll_relevant = state_enroll_df[(state_enroll_df['disability'] == 99) & (state_enroll_df['lep'] == 99)]\n",
    "    state_enroll_relevant = state_enroll_relevant.drop(columns=['disability', 'lep'])\n",
    "    \n",
    "    # We only want data with ncessch id\n",
    "    state_enroll_withid = state_enroll_relevant[~state_enroll_relevant['ncessch'].isna()]\n",
    "    \n",
    "    # We want proportion and check that with 99\n",
    "    state_enroll_final = state_enroll_withid[(state_enroll_withid['race'] == 99) | (state_enroll_withid['sex'] == 99)]\n",
    "    \n",
    "    return state_enroll_final\n",
    "\n",
    "\n",
    "arizona_enroll_2011 = enrollment_processor(twenty_eleven_enroll_df, 4)\n",
    "arizona_enroll_2013 = enrollment_processor(twenty_thirteen_enroll_df, 4)\n",
    "arizona_enroll_2015 = enrollment_processor(twenty_fifteen_enroll_df, 4)\n",
    "# We only care about schools that have AP passing one or more in previous table\n",
    "arizona_enroll_2011 = arizona_enroll_2011[arizona_enroll_2011['ncessch'].isin(arizona_2011['ncessch'])]\n",
    "arizona_enroll_2013 = arizona_enroll_2013[arizona_enroll_2013['ncessch'].isin(arizona_2013['ncessch'])]\n",
    "arizona_enroll_2015 = arizona_enroll_2015[arizona_enroll_2015['ncessch'].isin(arizona_2015['ncessch'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4919e73-321a-488d-9821-89edcb8dbf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "# Find the percentage of females and different races\n",
    "def find_percentage(dataframe):\n",
    "    total_enroll = dataframe[(dataframe['race'] == 99) & (dataframe['sex'] == 99)].copy()\n",
    "    total_enroll = total_enroll[['ncessch', 'enrollment_crdc']]\n",
    "    total_enroll.rename(columns={'enrollment_crdc' : 'total_enrollment'}, inplace=True)\n",
    "    \n",
    "    merged_total_df = pd.merge(total_enroll, dataframe)\n",
    "    \n",
    "    # Find percentage of female and merge\n",
    "    female_df = merged_total_df[(merged_total_df['sex'] == 2) & (merged_total_df['race'] == 99)].copy()\n",
    "    female_df['% female'] = female_df['enrollment_crdc'] / female_df['total_enrollment']\n",
    "    female_df = female_df[['ncessch', '% female']]\n",
    "    \n",
    "    \n",
    "    white_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 1)].copy()\n",
    "    white_df['% white'] = white_df['enrollment_crdc'] / white_df['total_enrollment']\n",
    "    white_df = white_df[['ncessch', '% white']]\n",
    "    \n",
    "    black_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 2)].copy()\n",
    "    black_df['% black'] = black_df['enrollment_crdc'] / black_df['total_enrollment']\n",
    "    black_df = black_df[['ncessch', '% black']]\n",
    "    \n",
    "    hispanic_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 3)].copy()\n",
    "    hispanic_df['% hispanic'] = hispanic_df['enrollment_crdc'] / hispanic_df['total_enrollment']\n",
    "    hispanic_df = hispanic_df[['ncessch', '% hispanic']]\n",
    "    \n",
    "    asian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 4)].copy()\n",
    "    asian_df['% asian'] = asian_df['enrollment_crdc'] / asian_df['total_enrollment']\n",
    "    asian_df = asian_df[['ncessch', '% asian']]\n",
    "    \n",
    "    american_indian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 5)].copy()\n",
    "    american_indian_df['% american_indian'] = american_indian_df['enrollment_crdc'] / american_indian_df['total_enrollment']\n",
    "    american_indian_df = american_indian_df[['ncessch', '% american_indian']]\n",
    "    \n",
    "    native_hawaiian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 6)].copy()\n",
    "    native_hawaiian_df['% native_hawaiian'] = native_hawaiian_df['enrollment_crdc'] / native_hawaiian_df['total_enrollment']\n",
    "    native_hawaiian_df = native_hawaiian_df[['ncessch', '% native_hawaiian']]\n",
    "    \n",
    "    twoormore_races_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 7)].copy()\n",
    "    twoormore_races_df['% two_or_more_races'] = twoormore_races_df['enrollment_crdc'] / twoormore_races_df['total_enrollment']\n",
    "    twoormore_races_df = twoormore_races_df[['ncessch', '% two_or_more_races']]\n",
    "    \n",
    "    merge_female_df = pd.merge(dataframe, female_df, on='ncessch')\n",
    "    merge_white_df = pd.merge(merge_female_df, white_df, on='ncessch')\n",
    "    merge_black_df = pd.merge(merge_white_df, black_df, on='ncessch')\n",
    "    merge_hispanic_df = pd.merge(merge_black_df, hispanic_df, on='ncessch')\n",
    "    merge_asian_df = pd.merge(merge_hispanic_df, asian_df, on='ncessch')\n",
    "    merge_american_indian_df = pd.merge(merge_asian_df, american_indian_df, on='ncessch')\n",
    "    merge_native_hawaiian_df = pd.merge(merge_american_indian_df, native_hawaiian_df, on='ncessch')\n",
    "    merge_twoormorerace_df = pd.merge(merge_native_hawaiian_df, twoormore_races_df, on='ncessch')\n",
    "    final_df = pd.merge(merge_twoormorerace_df, total_enroll, on='ncessch')\n",
    "    \n",
    "    final_df = final_df[(final_df['race'] == 99) & (final_df['sex'] == 99)]\n",
    "    final_df = final_df.drop(columns=['race', 'sex', 'enrollment_crdc', 'leaid'])\n",
    "    return final_df\n",
    "\n",
    "def get_info_df(percentage_df, score_df):\n",
    "    \n",
    "    info_df = pd.merge(percentage_df, score_df, on='ncessch')\n",
    "    year_col = info_df['year_y']\n",
    "    info_df = info_df.drop(columns=['year_x', 'year_y'])\n",
    "    info_df.insert(1, 'year', year_col)\n",
    "    return info_df\n",
    "\n",
    "arizona_2011_enroll_percent = find_percentage(arizona_enroll_2011)\n",
    "arizona_2013_enroll_percent = find_percentage(arizona_enroll_2013)\n",
    "arizona_2015_enroll_percent = find_percentage(arizona_enroll_2015)\n",
    "\n",
    "arizona_2011_info_df = get_info_df(arizona_2011_enroll_percent, arizona_2011)\n",
    "arizona_2013_info_df = get_info_df(arizona_2013_enroll_percent, arizona_2013)\n",
    "arizona_2015_info_df = get_info_df(arizona_2015_enroll_percent, arizona_2015)\n",
    "print(arizona_2011_info_df['ncessch'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b3fcd7-7c00-494c-909b-78c637f73ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concat Data for training purpose\n",
    "# Planning to use 2011 and 2013 for training\n",
    "train_data = pd.concat([arizona_2011_info_df, arizona_2013_info_df], ignore_index = True)\n",
    "train_feature = train_data.drop(columns=['students_AP_pass_oneormore'])\n",
    "train_target = train_data[['students_AP_pass_oneormore']]\n",
    "\n",
    "# Test Data is 2015 without passing info\n",
    "test_data = arizona_2015_info_df\n",
    "test_feature = test_data.drop(columns=['students_AP_pass_oneormore'])\n",
    "test_target = test_data[['students_AP_pass_oneormore']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf82bf1-464b-47d1-a648-d9bc7b1ae79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_feature)\n",
    "X_test = scaler.transform(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cdf6f2-1fd8-4792-af48-946267ef1be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 400001.0: Mean Residual = 114.00\n",
      "District 400019.0: Mean Residual = 10.00\n",
      "District 400026.0: Mean Residual = 8.00\n",
      "District 400056.0: Mean Residual = -162.00\n",
      "District 400065.0: Mean Residual = 0.00\n",
      "District 400081.0: Mean Residual = 39.00\n",
      "District 400097.0: Mean Residual = 45.00\n",
      "District 400112.0: Mean Residual = 32.00\n",
      "District 400129.0: Mean Residual = 5.00\n",
      "District 400202.0: Mean Residual = 3.00\n",
      "District 400211.0: Mean Residual = 4.00\n",
      "District 400223.0: Mean Residual = 1.00\n",
      "District 400225.0: Mean Residual = 67.50\n",
      "District 400327.0: Mean Residual = -9.00\n",
      "District 400427.0: Mean Residual = -182.00\n",
      "District 400432.0: Mean Residual = 0.00\n",
      "District 400450.0: Mean Residual = 10.38\n",
      "District 400608.0: Mean Residual = 123.00\n",
      "District 400653.0: Mean Residual = -8.00\n",
      "District 400680.0: Mean Residual = 55.33\n",
      "District 400778.0: Mean Residual = -3.00\n",
      "District 400790.0: Mean Residual = -17.00\n",
      "District 400818.0: Mean Residual = -67.00\n",
      "District 400829.0: Mean Residual = -28.00\n",
      "District 400830.0: Mean Residual = 71.00\n",
      "District 400831.0: Mean Residual = -89.00\n",
      "District 400843.0: Mean Residual = 2.00\n",
      "District 400862.0: Mean Residual = -7.00\n",
      "District 400878.0: Mean Residual = 130.50\n",
      "District 400897.0: Mean Residual = -78.00\n",
      "District 400898.0: Mean Residual = -96.00\n",
      "District 400903.0: Mean Residual = 20.00\n",
      "District 400904.0: Mean Residual = -48.00\n",
      "District 400909.0: Mean Residual = 1.00\n",
      "District 401180.0: Mean Residual = 0.00\n",
      "District 401410.0: Mean Residual = 3.67\n",
      "District 401460.0: Mean Residual = 66.00\n",
      "District 401740.0: Mean Residual = 13.00\n",
      "District 401760.0: Mean Residual = -192.50\n",
      "District 401870.0: Mean Residual = -50.53\n",
      "District 402320.0: Mean Residual = 0.00\n",
      "District 402530.0: Mean Residual = -27.00\n",
      "District 402690.0: Mean Residual = 21.50\n",
      "District 402860.0: Mean Residual = -2.00\n",
      "District 402920.0: Mean Residual = 91.00\n",
      "District 403010.0: Mean Residual = 47.00\n",
      "District 403040.0: Mean Residual = -13.00\n",
      "District 403400.0: Mean Residual = 24.17\n",
      "District 403450.0: Mean Residual = 95.17\n",
      "District 403780.0: Mean Residual = 18.50\n",
      "District 403870.0: Mean Residual = 40.00\n",
      "District 403990.0: Mean Residual = 6.00\n",
      "District 404630.0: Mean Residual = -28.00\n",
      "District 404720.0: Mean Residual = 21.00\n",
      "District 404970.0: Mean Residual = -39.33\n",
      "District 405070.0: Mean Residual = 13.00\n",
      "District 405320.0: Mean Residual = 3.00\n",
      "District 405530.0: Mean Residual = -3.00\n",
      "District 405820.0: Mean Residual = 7.00\n",
      "District 405930.0: Mean Residual = 49.60\n",
      "District 406070.0: Mean Residual = 61.00\n",
      "District 406250.0: Mean Residual = 25.71\n",
      "District 406330.0: Mean Residual = -23.18\n",
      "District 406580.0: Mean Residual = -27.00\n",
      "District 406730.0: Mean Residual = -43.00\n",
      "District 407300.0: Mean Residual = 58.50\n",
      "District 407570.0: Mean Residual = 60.20\n",
      "District 407700.0: Mean Residual = 17.00\n",
      "District 407750.0: Mean Residual = 20.80\n",
      "District 408170.0: Mean Residual = 49.00\n",
      "District 408280.0: Mean Residual = -16.00\n",
      "District 408340.0: Mean Residual = -0.70\n",
      "District 408520.0: Mean Residual = -2.83\n",
      "District 408800.0: Mean Residual = 60.50\n",
      "District 408850.0: Mean Residual = 46.75\n",
      "District 409190.0: Mean Residual = -39.00\n",
      "District 409460.0: Mean Residual = 18.00\n",
      "District 409630.0: Mean Residual = 3.80\n",
      "District 409733.0: Mean Residual = -96.00\n"
     ]
    }
   ],
   "source": [
    "# Use DecisionTreeRegressor to fit the model\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "model = DecisionTreeRegressor(random_state = 482)\n",
    "\n",
    "# Function to fit and predict different metrics\n",
    "def predictor():\n",
    "    \n",
    "    # Fit and predict students_AP_exam_none\n",
    "    model.fit(X_train, train_target)\n",
    "    predict_ap_passing = model.predict(X_test)\n",
    "    test_result = test_data.copy()\n",
    "    test_result.rename(columns={'students_AP_pass_oneormore' : 'actual_students_AP_pass_oneormore'}, inplace=True)\n",
    "    test_result['predicted_students_AP_pass_oneormore'] = predict_ap_passing\n",
    "    test_result = pd.merge(test_result, arizona_2015_district, on='ncessch')\n",
    "    return test_result\n",
    "    \n",
    "test_result = predictor()\n",
    "\n",
    "# Calculate the MSE by each district\n",
    "grouped = test_result.groupby('leaid')\n",
    "rmse_by_district = {}\n",
    "mean_residual_by_district = {}\n",
    "\n",
    "for district_id, group in grouped:\n",
    "    # rmse = mean_squared_error(group['actual_students_AP_pass_oneormore'], group['predicted_students_AP_pass_oneormore'])\n",
    "    # rmse_by_district[district_id] = rmse\n",
    "    \n",
    "    mean_residual = (group['actual_students_AP_pass_oneormore'] - group['predicted_students_AP_pass_oneormore']).mean()\n",
    "    mean_residual_by_district[district_id] = mean_residual\n",
    "    \n",
    "# for district_id, mse in mse_by_district.items():\n",
    "#     print(f\"District {district_id}: MSE = {mse:.2f}\")    \n",
    "    \n",
    "for district_id, mean_residual in  mean_residual_by_district.items():\n",
    "    print(f\"District {district_id}: Mean Residual = {mean_residual:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc871177-0dd3-4f92-9f89-66667d522a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse     118.498262\n",
      "mae       75.645078\n",
      "count    193.000000\n",
      "dtype: float64\n",
      "                rmse     mae  count\n",
      "leaid                              \n",
      "400001.0  114.000000  114.00    1.0\n",
      "400019.0   10.000000   10.00    1.0\n",
      "400026.0    8.000000    8.00    1.0\n",
      "400056.0  162.000000  162.00    1.0\n",
      "400065.0    0.000000    0.00    1.0\n",
      "...              ...     ...    ...\n",
      "408850.0   95.910114   87.25    4.0\n",
      "409190.0   39.000000   39.00    1.0\n",
      "409460.0   18.000000   18.00    1.0\n",
      "409630.0   77.641484   62.60    5.0\n",
      "409733.0   96.000000   96.00    1.0\n",
      "\n",
      "[79 rows x 3 columns]\n",
      "rmse     273.987226\n",
      "mae      243.588235\n",
      "count     16.000000\n",
      "dtype: float64\n",
      "rmse     0.000000\n",
      "mae      0.000000\n",
      "count    0.058824\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import count\n",
    "\n",
    "districts = test_result['leaid']\n",
    "y_true = test_result['actual_students_AP_pass_oneormore']\n",
    "y_pred = test_result['predicted_students_AP_pass_oneormore']\n",
    "regression_metrics = {\n",
    "    'rmse': root_mean_squared_error,\n",
    "    'mae': mean_absolute_error,\n",
    "    'count': count\n",
    "}\n",
    "\n",
    "mf = MetricFrame(metrics=regression_metrics, y_true=y_true, y_pred=y_pred, sensitive_features=districts)\n",
    "\n",
    "print(mf.overall)\n",
    "print(mf.by_group)\n",
    "print(mf.difference())\n",
    "print(mf.ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b611ad7-88db-47d3-a01b-2a37756a8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(100,50), dpi=300)\n",
    "# plot_tree(model, filled=True, feature_names=train_feature.columns, rounded=True, fontsize=7)\n",
    "# plt.savefig('APEducationData/decision_tree_plot.png', bbox_inches='tight')  # Save the plot to a file\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d854c-abcd-4065-b1f6-b86adf47cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modules",
   "language": "python",
   "name": "haytham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

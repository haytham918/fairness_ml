{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e90f30-03a7-43ee-ac65-6118297932d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "# pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58c6149-c4e0-4089-b40d-93466ab082fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twenty_eleven_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2011.csv', low_memory=False)\n",
    "twenty_thirteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2013.csv', low_memory=False)\n",
    "twenty_fifteen_df = pd.read_csv('APEducationData/schools_crdc_ap_exams_2015.csv', low_memory=False)\n",
    "\n",
    "# 2017's data has a lot of missing values and negative values. We don't consider using it at this moment\n",
    "# twenty_seventeen_df = pd.read_csv('schools_crdc_ap_exams_2017.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deeb8ed3-02b9-4ca7-8113-0b6f833a115d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Enrollment Data\n",
    "twenty_eleven_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2011.csv\", low_memory=False)\n",
    "twenty_thirteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2013.csv\", low_memory=False)\n",
    "twenty_fifteen_enroll_df = pd.read_csv(\"APEducationData/schools_crdc_enrollment_k12_2015.csv\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "26d2ed74-c786-4c81-a9dc-a230c3cfbe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weird_twenty_eleven_df = twenty_eleven_df[\n",
    "#     ((twenty_eleven_df['students_AP_exam_oneormore'] > twenty_eleven_df['students_AP_pass_oneormore']) & (twenty_eleven_df['students_AP_pass_oneormore'] >= 0)) | \n",
    "#     ((twenty_eleven_df['students_AP_exam_all'] > twenty_eleven_df['students_AP_exam_oneormore']) & (twenty_eleven_df['students_AP_exam_oneormore'] >= 0)) |\n",
    "#     ((twenty_eleven_df['students_AP_pass_all'] > twenty_eleven_df['students_AP_exam_all']) & (twenty_eleven_df['students_AP_exam_all'] >= 0))\n",
    "                                                                                                                        \n",
    "# ]\n",
    "# number_schools = weird_twenty_eleven_df['crdc_id'].nunique()\n",
    "# print(len(weird_twenty_eleven_df))\n",
    "# print(number_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "622e4f27-0519-40fd-8206-123959622d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  students_AP_pass_oneormore       ncessch\n",
      "57839   2011                       129.0  4.000010e+10\n",
      "58379   2011                        11.0  4.000190e+10\n",
      "58709   2011                         4.0  4.000260e+10\n",
      "58979   2011                         4.0  4.000430e+10\n",
      "59669   2011                         4.0  4.000740e+10\n",
      "...      ...                         ...           ...\n",
      "115049  2011                         8.0  4.096300e+10\n",
      "115079  2011                        56.0  4.096300e+10\n",
      "115109  2011                        15.0  4.096300e+10\n",
      "115139  2011                        86.0  4.096300e+10\n",
      "115199  2011                         4.0  4.097330e+10\n",
      "\n",
      "[126 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# missing_id = twenty_eleven_df[twenty_eleven_df['ncessch'].isna()]\n",
    "# print(len(missing_id) / 30)\n",
    "\n",
    "# Function to process data that removes all NA rows or with negative values\n",
    "\n",
    "def data_validifier(dataframe, state_id):\n",
    "    # Getting rows with the required state_id\n",
    "    state_df = dataframe[dataframe['fips'] == state_id];\n",
    "    \n",
    "    # Aggregate Race and Sex\n",
    "    state_agg = state_df[(state_df['race'] == 99) & (state_df['sex'] == 99)]\n",
    "    \n",
    "    # Drop some columns we don't need at this moment\n",
    "    state_df_dropcolumn = state_agg.drop(columns=['students_AP_exam_all', 'students_AP_pass_all', 'fips', 'lep', 'disability', 'leaid', 'crdc_id', \n",
    "                                                'students_AP_exam_none', 'students_AP_pass_none', 'students_AP_exam_oneormore', 'sex', 'race'])\n",
    "    \n",
    "    # Drop NA Values(It's fine to have NA values for exam_all or pass_all\n",
    "    state_df_nona = state_df_dropcolumn.dropna()\n",
    "    \n",
    "    # Remove all rows with negative values\n",
    "    state_df_final = state_df_nona[(state_df_nona['students_AP_pass_oneormore'] >= 0)]\n",
    "    \n",
    "    return state_df_final\n",
    "\n",
    "# Get Arizona's valid df\n",
    "arizona_2011 = data_validifier(twenty_eleven_df, 4)\n",
    "arizona_2013 = data_validifier(twenty_thirteen_df, 4)\n",
    "arizona_2015 = data_validifier(twenty_fifteen_df, 4)\n",
    "\n",
    "print(arizona_2011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fb16ec2-c323-4e92-babb-ff45e8977388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n",
      "1250\n"
     ]
    }
   ],
   "source": [
    "# Function to process enrollment data\n",
    "def enrollment_processor(dataframe, state_id):\n",
    "    # Getting rows with the relevant state_id\n",
    "    state_enroll_df = dataframe[dataframe['fips'] == state_id]\n",
    "    \n",
    "    # Drop preenrollment \n",
    "    state_enroll_df = state_enroll_df.drop(columns=['psenrollment_crdc', 'crdc_id', 'fips'])\n",
    "    \n",
    "    # We need proportion of females and each races\n",
    "    # We don't care about disability or LEP here\n",
    "    state_enroll_relevant = state_enroll_df[(state_enroll_df['disability'] == 99) & (state_enroll_df['lep'] == 99)]\n",
    "    state_enroll_relevant = state_enroll_relevant.drop(columns=['disability', 'lep'])\n",
    "    \n",
    "    # We only want data with ncessch id\n",
    "    state_enroll_withid = state_enroll_relevant[~state_enroll_relevant['ncessch'].isna()]\n",
    "    \n",
    "    # We want proportion and check that with 99\n",
    "    state_enroll_final = state_enroll_withid[(state_enroll_withid['race'] == 99) | (state_enroll_withid['sex'] == 99)]\n",
    "    \n",
    "    return state_enroll_final\n",
    "\n",
    "\n",
    "arizona_enroll_2011 = enrollment_processor(twenty_eleven_enroll_df, 4)\n",
    "arizona_enroll_2013 = enrollment_processor(twenty_thirteen_enroll_df, 4)\n",
    "arizona_enroll_2015 = enrollment_processor(twenty_fifteen_enroll_df, 4)\n",
    "print(len(arkansas_enroll_2015))\n",
    "# We only care about schools that have AP passing one or more in previous table\n",
    "arizona_enroll_2011 = arizona_enroll_2011[arizona_enroll_2011['ncessch'].isin(arizona_2011['ncessch'])]\n",
    "arizona_enroll_2013 = arizona_enroll_2013[arizona_enroll_2013['ncessch'].isin(arizona_2013['ncessch'])]\n",
    "arizona_enroll_2015 = arizona_enroll_2015[arizona_enroll_2015['ncessch'].isin(arizona_2015['ncessch'])]\n",
    "\n",
    "print(len(arizona_enroll_2011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4919e73-321a-488d-9821-89edcb8dbf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# Find the percentage of females and different races\n",
    "def find_percentage(dataframe):\n",
    "    total_enroll = dataframe[(dataframe['race'] == 99) & (dataframe['sex'] == 99)].copy()\n",
    "    total_enroll = total_enroll[['ncessch', 'enrollment_crdc']]\n",
    "    total_enroll.rename(columns={'enrollment_crdc' : 'total_enrollment'}, inplace=True)\n",
    "    \n",
    "    merged_total_df = pd.merge(total_enroll, dataframe)\n",
    "    \n",
    "    # Find percentage of female and merge\n",
    "    female_df = merged_total_df[(merged_total_df['sex'] == 2) & (merged_total_df['race'] == 99)].copy()\n",
    "    female_df['% female'] = female_df['enrollment_crdc'] / female_df['total_enrollment']\n",
    "    female_df = female_df[['ncessch', '% female']]\n",
    "    \n",
    "    \n",
    "    white_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 1)].copy()\n",
    "    white_df['% white'] = white_df['enrollment_crdc'] / white_df['total_enrollment']\n",
    "    white_df = white_df[['ncessch', '% white']]\n",
    "    \n",
    "    black_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 2)].copy()\n",
    "    black_df['% black'] = black_df['enrollment_crdc'] / black_df['total_enrollment']\n",
    "    black_df = black_df[['ncessch', '% black']]\n",
    "    \n",
    "    hispanic_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 3)].copy()\n",
    "    hispanic_df['% hispanic'] = hispanic_df['enrollment_crdc'] / hispanic_df['total_enrollment']\n",
    "    hispanic_df = hispanic_df[['ncessch', '% hispanic']]\n",
    "    \n",
    "    asian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 4)].copy()\n",
    "    asian_df['% asian'] = asian_df['enrollment_crdc'] / asian_df['total_enrollment']\n",
    "    asian_df = asian_df[['ncessch', '% asian']]\n",
    "    \n",
    "    american_indian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 5)].copy()\n",
    "    american_indian_df['% american_indian'] = american_indian_df['enrollment_crdc'] / american_indian_df['total_enrollment']\n",
    "    american_indian_df = american_indian_df[['ncessch', '% american_indian']]\n",
    "    \n",
    "    native_hawaiian_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 6)].copy()\n",
    "    native_hawaiian_df['% native_hawaiian'] = native_hawaiian_df['enrollment_crdc'] / native_hawaiian_df['total_enrollment']\n",
    "    native_hawaiian_df = native_hawaiian_df[['ncessch', '% native_hawaiian']]\n",
    "    \n",
    "    twoormore_races_df = merged_total_df[(merged_total_df['sex'] == 99) & (merged_total_df['race'] == 7)].copy()\n",
    "    twoormore_races_df['% two_or_more_races'] = twoormore_races_df['enrollment_crdc'] / twoormore_races_df['total_enrollment']\n",
    "    twoormore_races_df = twoormore_races_df[['ncessch', '% two_or_more_races']]\n",
    "    \n",
    "    merge_female_df = pd.merge(dataframe, female_df, on='ncessch')\n",
    "    merge_white_df = pd.merge(merge_female_df, white_df, on='ncessch')\n",
    "    merge_black_df = pd.merge(merge_white_df, black_df, on='ncessch')\n",
    "    merge_hispanic_df = pd.merge(merge_black_df, hispanic_df, on='ncessch')\n",
    "    merge_asian_df = pd.merge(merge_hispanic_df, asian_df, on='ncessch')\n",
    "    merge_american_indian_df = pd.merge(merge_asian_df, american_indian_df, on='ncessch')\n",
    "    merge_native_hawaiian_df = pd.merge(merge_american_indian_df, native_hawaiian_df, on='ncessch')\n",
    "    merge_twoormorerace_df = pd.merge(merge_native_hawaiian_df, twoormore_races_df, on='ncessch')\n",
    "    final_df = pd.merge(merge_twoormorerace_df, total_enroll, on='ncessch')\n",
    "    \n",
    "    final_df = final_df[(final_df['race'] == 99) & (final_df['sex'] == 99)]\n",
    "    final_df = final_df.drop(columns=['race', 'sex', 'enrollment_crdc'])\n",
    "    return final_df\n",
    "\n",
    "def get_info_df(percentage_df, score_df):\n",
    "    \n",
    "    info_df = pd.merge(percentage_df, score_df, on='ncessch')\n",
    "    year_col = info_df['year_y']\n",
    "    info_df = info_df.drop(columns=['year_x', 'year_y'])\n",
    "    info_df.insert(1, 'year', year_col)\n",
    "    return info_df\n",
    "\n",
    "arizona_2011_enroll_percent = find_percentage(arizona_enroll_2011)\n",
    "arizona_2013_enroll_percent = find_percentage(arizona_enroll_2011)\n",
    "arizona_2011_info_df = get_info_df(find_percentage(arizona_enroll_2011), arizona_2011)\n",
    "arizona_2013_info_df = get_info_df(find_percentage(arizona_enroll_2013), arizona_2013)\n",
    "arizona_2015_info_df = get_info_df(find_percentage(arizona_enroll_2015), arizona_2015)\n",
    "print(arizona_2011_info_df['ncessch'].nunique())\n",
    "print(arizona_2011_info_df['leaid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414aa14-80b4-47a6-8f21-0e29c7494683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0b3fcd7-7c00-494c-909b-78c637f73ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ncessch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000010e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.000201e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  race       ncessch\n",
       "0     1   1.0  6.000010e+10\n",
       "1     1   3.0  6.000010e+10\n",
       "2     1  99.0  6.000010e+10\n",
       "3     2   1.0  6.000010e+10\n",
       "4     2  99.0  6.000010e+10\n",
       "..  ...   ...           ...\n",
       "95    2   1.0  6.000201e+10\n",
       "96    2   4.0  6.000201e+10\n",
       "97    2  99.0  6.000201e+10\n",
       "98   99   1.0  6.000201e+10\n",
       "99   99   4.0  6.000201e+10\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat Data for training purpose\n",
    "# Planning to use 2011 and 2013 for training\n",
    "\n",
    "train_data = pd.concat([california_2011, california_2013], ignore_index = True)\n",
    "\n",
    "# Drop the year column \n",
    "# Reset Index for test data\n",
    "# train_data = train_data.drop(columns=['year'])\n",
    "# test_data = california_2015.drop(columns=['year']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_feature = train_data.drop(columns=['students_AP_pass_none', 'students_AP_exam_none', 'students_AP_exam_oneormore', 'students_AP_pass_oneormore'])\n",
    "train_none_ap = train_data['students_AP_exam_none']\n",
    "train_none_passing = train_data['students_AP_pass_none']\n",
    "train_oneormore_ap = train_data['students_AP_exam_oneormore']\n",
    "train_oneormore_passing = train_data['students_AP_pass_oneormore']\n",
    "\n",
    "test_feature = test_data.drop(columns=['students_AP_pass_none', 'students_AP_exam_none', 'students_AP_exam_oneormore', 'students_AP_pass_oneormore'])\n",
    "test_none_ap = test_data['students_AP_exam_none']\n",
    "test_none_passing = test_data['students_AP_pass_none']\n",
    "test_oneormore_ap = test_data['students_AP_exam_oneormore']\n",
    "test_oneormore_passing = test_data['students_AP_pass_oneormore']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2bf82bf1-464b-47d1-a648-d9bc7b1ae79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_feature)\n",
    "X_test = scaler.transform(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76cdf6f2-1fd8-4792-af48-946267ef1be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Students Taking No AP exams in California in 2015:  1696.0434014657346\n",
      "MSE for Students Passing No AP exams in California in 2015:  1816.2829910415514\n",
      "MSE for Students Taking One or More AP exams in California in 2015:  12083.408802793369\n",
      "MSE for Students Passing One or More AP exams in California in 2015:  5679.750827187407\n"
     ]
    }
   ],
   "source": [
    "# Use RandomForestRegressor to fit the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = RandomForestRegressor(random_state = 482)\n",
    "\n",
    "# Function to fit and predict different metrics\n",
    "def predictor():\n",
    "    \n",
    "    # Fit and predict students_AP_exam_none\n",
    "    model.fit(X_train, train_none_ap)\n",
    "    predict_none_ap = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_pass_none    \n",
    "    model.fit(X_train, train_none_passing)\n",
    "    predict_none_passing = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_exam_oneormore\n",
    "    model.fit(X_train, train_oneormore_ap)\n",
    "    predict_oneormore_ap = model.predict(X_test)\n",
    "    \n",
    "    # Fit and predict students_AP_pass_oneormore\n",
    "    model.fit(X_train, train_oneormore_passing)\n",
    "    predict_oneormore_passing = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MSE metrics for each\n",
    "    none_ap_mse = mean_squared_error(predict_none_ap, test_none_ap)\n",
    "    none_passing_mse = mean_squared_error(predict_none_passing, test_none_passing)\n",
    "    oneormore_ap_mse = mean_squared_error(predict_oneormore_ap, test_oneormore_ap)\n",
    "    oneormore_passing_mse = mean_squared_error(predict_oneormore_passing, test_oneormore_passing)\n",
    "    \n",
    "    return none_ap_mse, none_passing_mse, oneormore_ap_mse, oneormore_passing_mse\n",
    "\n",
    "none_ap_mse, none_passing_mse, oneormore_ap_mse, oneormore_passing_mse = predictor()\n",
    "print(\"MSE for Students Taking No AP exams in California in 2015: \", none_ap_mse)\n",
    "print(\"MSE for Students Passing No AP exams in California in 2015: \", none_passing_mse)\n",
    "print(\"MSE for Students Taking One or More AP exams in California in 2015: \", oneormore_ap_mse)\n",
    "print(\"MSE for Students Passing One or More AP exams in California in 2015: \", oneormore_passing_mse)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d854c-abcd-4065-b1f6-b86adf47cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modules",
   "language": "python",
   "name": "haytham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
